{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Various Machine Learning Models for Handwritten Character Recognition\n",
    "This is our Jupiter Notebook run the code we used to produce results step-by-step.\n",
    "\n",
    "Import necessary helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from testing_models import evaluate_model, test_model_nn\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import get_data\n",
    "from classifiers import *\n",
    "from nn import *\n",
    "from joblib import load\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skopt.space import Integer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data\n",
    "We used data from the Alpha_Num dataset on kaggle. It contains over 108000 images of handwritten characters. Each image is approximately 28x28 pixels and is in gray-scale. However, before we can train the models we preprocessed them to ensure each image had the same features:\n",
    "* 28x28 pixels: any image less than 28x28 was padded\n",
    "* Gray-Scale\n",
    "\n",
    "For more information on getting data please refer to **preprocess.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data(\"train\", \"ascii_file_counts.csv\")\n",
    "X_test, y_test = get_data(\"test\", \"ascii_file_counts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Training Traditional Machine Learning Models\n",
    "In this section we will train (or load) and show a brief testing of the following models:\n",
    "* XGBoost\n",
    "* Random Forest\n",
    "* K-Nearest Neighbors\n",
    "\n",
    "The actual results and comparision of models will be done after this section where models are trained (or loaded)\n",
    "\n",
    "## 2.1 Training Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier()\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': (10, 500),  # Number of trees\n",
    "    'max_depth': (1, 100),  # Maximum depth\n",
    "    'min_samples_split': (2, 20),  # Minimum number of samples to split\n",
    "    'min_samples_leaf': (1, 20),  # Minimum number of samples to be leaf\n",
    "    'max_features': ['sqrt', 'log2', None],  # Features to consider\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # Measure for split quality\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None],  # Class weights for handling imbalances\n",
    "}\n",
    "\n",
    "bayes_opt = BayesSearchCV(\n",
    "    estimator=RF_model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=30,\n",
    "    cv=5,       # 5-folds\n",
    "    scoring='neg_mean_squared_error',  # Objective function to minimize MSE\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We offer 2 methods to get the Random Forest Model. We trained the model using the code block with the training loop. However, this takes time, so if you want you can directly load the model we provided using the second code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_opt.fit(X_train, y_train)\n",
    "RF_model = bayes_opt.best_estimator_\n",
    "RF_bayes_df = pd.DataFrame(bayes_opt.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_data = pd.read_csv(\"RF_bayes_df.csv\")\n",
    "RF_model = RandomForestClassifier(class_weight= 'balanced', criterion= 'log_loss', max_depth= 41, max_features= 'sqrt', min_samples_leaf= 1, min_samples_split= 6, n_estimators= 497, random_state =42)\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "acc_list = []\n",
    "prec_list = []\n",
    "recall_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, acc, cm, prec, recall = evaluate_model(y_test, RF_model.predict(X_test))\n",
    "\n",
    "f1_list.append(f1)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "\n",
    "print(f\"Random Forest: \\n\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Confusion Matrix: \\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model = XGBClassifier(objective='multi:softprob',num_class=93,booster='gbtree',eval_metric= 'mlogloss')\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': Integer(50, 300),        # Number of trees\n",
    "    'max_depth': Integer(3, 30),             # Depth of each tree     \n",
    "}\n",
    "\n",
    "bayes_opt = BayesSearchCV(\n",
    "    estimator=XG_model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=30,\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # Objective function: MSE\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_opt.fit(X_train, y_train)\n",
    "XG_model = bayes_opt.best_estimator_\n",
    "XG_bayes_df = pd.DataFrame(bayes_opt.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model = load('xgboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, acc, cm, prec, recall = evaluate_model(y_test, XG_model.predict(X_test))\n",
    "\n",
    "f1_list.append(f1)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "\n",
    "print(f\"XGBoost: \\n\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Confusion Matrix: \\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier(weights=\"distance\")\n",
    "\n",
    "param_space = {\n",
    "    'n_neighbors': Integer(1,200)      # Minimum samples per leaf\n",
    "}\n",
    "\n",
    "bayes_opt = BayesSearchCV(\n",
    "    estimator= KNN_model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=20, \n",
    "    cv=5,    \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_opt.fit(X_train, y_train)\n",
    "KNN_model = bayes_opt.best_estimator_\n",
    "KNN_bayes_df = pd.DataFrame(bayes_opt.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = load('knn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, acc, cm, prec, recall = evaluate_model(y_test, KNN_model.predict(X_test))\n",
    "\n",
    "f1_list.append(f1)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "\n",
    "print(f\"KNN: \\n\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Confusion Matrix: \\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Training Neural Network Models\n",
    "In this section we will train (or load) and show a brief testing of the following models:\n",
    "* Feed Forward Neural Network\n",
    "* CNN (Convolutional Neural Network )\n",
    "* Transformer (With CNN features)\n",
    "\n",
    "The details of each model and the PyTorch implementation as well as the training loop details can be found in the **nn.py** file.\n",
    "\n",
    "## Initializing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "num_classes = 93\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "dataset = AlphaNumDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"train\")\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataset_test = AlphaNumDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"test\")\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = AlphaNumDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"validation\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Training Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FF_model = FeedForwardNN(input_size=input_size, num_classes=num_classes, hidden_size=288).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(FF_model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(num_epochs, data_loader, val_loader, device, FF_model, criterion, optimizer, scheduler, patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_model = torch.load('FeedForward.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing + Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, acc, prec, recall = test_model_nn(FF_model, data_loader_test, device, criterion)\n",
    "\n",
    "f1_list.append(f1)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "\n",
    "print(f\"Feed Forward Neural Network: \\n\")\n",
    "print(f\"F1 Score (Weighted Among Classes): {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision (Weighted Among Classes): {prec}\")\n",
    "print(f\"Recalln (Weighted Among Classes): {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CNN_model = CNN(n_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(num_epochs, data_loader, val_loader, device, CNN_model, criterion, optimizer, scheduler, patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = torch.load('cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing + Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,acc,prec,recall = test_model_nn(CNN_model,data_loader_test, device, criterion)\n",
    "\n",
    "f1_list.append(f1)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "\n",
    "print(f\"Feed Forward Neural Network: \\n\")\n",
    "print(f\"F1 Score (Weighted Among Classes): {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision (Weighted Among Classes): {prec}\")\n",
    "print(f\"Recalln (Weighted Among Classes): {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Training Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformer_model = CNNTransformer(n_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "optimizer = optim.Adam(transformer_model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)  # Reduce LR by 10x every 5 epochs\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(num_epochs, data_loader, val_loader, device, transformer_model, criterion, optimizer, scheduler, patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = torch.load('transformer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing + Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,acc,prec,recall = test_model_nn(transformer_model,data_loader_test, device, criterion)\n",
    "\n",
    "f1_list.append(f1)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "\n",
    "print(f\"Feed Forward Neural Network: \\n\")\n",
    "print(f\"F1 Score (Weighted Among Classes): {f1}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Precision (Weighted Among Classes): {prec}\")\n",
    "print(f\"Recalln (Weighted Among Classes): {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 All Model Metric Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "models = ['Random Forest', 'XGBoost', 'KNN', 'Feed Forward', 'CNN', 'Transformer']\n",
    "colors = ['blue', 'green', 'purple', 'red','orange','yellow']\n",
    "\n",
    "bars = axes[0, 0].bar(models, f1_list, color=colors, alpha=0.7)\n",
    "axes[0, 0].bar(models, f1_list, color=colors, alpha=0.7)\n",
    "axes[0, 0].set_title(\"F1 Scores by Model\")\n",
    "axes[0,0].set_ylim(0.6, 1) \n",
    "axes[0,0].bar_label(bars, fmt='%.2f')\n",
    "\n",
    "bars = axes[0,1].bar(models, acc_list)\n",
    "axes[0, 1].bar(models, acc_list, color=colors, alpha=0.7)\n",
    "axes[0, 1].set_title(\"Accuracy by Model\")\n",
    "axes[0, 1].set_ylim(0.6, 1) \n",
    "axes[0,1].bar_label(bars, fmt='%.2f')\n",
    "\n",
    "bars = axes[1,0].bar(models, prec_list)\n",
    "axes[1, 0].bar(models, prec_list, color=colors, alpha=0.7)\n",
    "axes[1, 0].set_title(\"Precision by Model\")\n",
    "axes[1, 0].set_ylim(0.6, 1) \n",
    "axes[1,0].bar_label(bars, fmt='%.2f')\n",
    "\n",
    "bars = axes[1,1].bar(models, recall_list)\n",
    "axes[1, 1].bar(models, recall_list, color=colors, alpha=0.7)\n",
    "axes[1, 1].set_title(\"Recall by Model\")\n",
    "axes[1, 1].set_ylim(0.6, 1) \n",
    "axes[1,1].bar_label(bars, fmt='%.2f')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Runtime Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runtime vs. accuracy\n",
    "rf_runtime, xgboost_runtime, knn_runtime = 8.8, 25.63, .66\n",
    "ff_runtime, cnn_runtime, transformer_runtime = 6.38, 7.72, 49.12\n",
    "\n",
    "runtimes = [rf_runtime, xgboost_runtime, knn_runtime, ff_runtime, cnn_runtime, transformer_runtime]\n",
    "labels = ['RF','XGBoost', 'KNN', 'FeedForward', 'CNN', 'Transformer']\n",
    "\n",
    "for i in range(len(runtimes)):\n",
    "    plt.scatter(runtimes[i], acc_list[i], label=labels[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Runtime vs. Accuracy\")\n",
    "plt.xlabel('Runtime in minutes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6)) \n",
    "bars = plt.bar(models, runtimes, color=colors, alpha=0.7)  \n",
    "plt.bar_label(bars, fmt='%.2f')\n",
    "plt.title(\"Total Training Runtime\")\n",
    "plt.ylabel('Runtime in minutes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Bayesian Optimization Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_data = pd.read_csv('RF_bayes_df.csv')\n",
    "n_estimators = forest_data['param_n_estimators']\n",
    "mean_test_score = forest_data['mean_test_score']\n",
    "mean_test_score = -mean_test_score\n",
    "sorted_indices = n_estimators.argsort()\n",
    "n_estimators_sorted = n_estimators.iloc[sorted_indices]\n",
    "mean_test_score_sorted = mean_test_score.iloc[sorted_indices]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_sorted, mean_test_score_sorted, marker='o', linestyle='-')\n",
    "plt.title('Bayesian Optimization for Random Forest')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.grid()\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Optimization Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pd = pd.read_csv('knn_opti.csv')\n",
    "\n",
    "n_neighbors = knn_pd['param_n_neighbors']\n",
    "mean_test_score = knn_pd['mean_test_score']\n",
    "\n",
    "accuracy = -mean_test_score  \n",
    "\n",
    "sorted_indices = n_neighbors.argsort()\n",
    "n_estimators_sorted = n_neighbors.iloc[sorted_indices]\n",
    "accuracy_sorted = accuracy.iloc[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_sorted, accuracy_sorted, marker='o', linestyle='-')\n",
    "plt.title('n_neighbors vs MSE')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
