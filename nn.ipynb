{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from nn import CustomImageDataset, FeedForwardNN, test_model, validate, CNN, train_model, set_seed, CNN_LSTM, CNNTransformer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28  # Flattened image size (28x28)\n",
    "num_classes = 94  # Number of classes (modify if needed)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "set_seed(42)\n",
    "\n",
    "dataset = CustomImageDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"train\")\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataset_test = CustomImageDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"test\")\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = CustomImageDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"validation\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, and Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeedForwardNN(input_size=input_size, num_classes=num_classes, hidden_size=288).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)  # Reduce LR by 10x every 5 epochs\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training step\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation step\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(data_loader):.4f}, \"\n",
    "          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        print(\"Validation loss improved! Saving model...\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 2.7277, Validation Loss: 1.9541, Validation Accuracy: 46.16%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [2/20], Train Loss: 1.6439, Validation Loss: 1.6032, Validation Accuracy: 54.42%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [3/20], Train Loss: 1.3561, Validation Loss: 1.2871, Validation Accuracy: 63.24%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [4/20], Train Loss: 1.2007, Validation Loss: 1.3199, Validation Accuracy: 61.48%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [5/20], Train Loss: 1.1048, Validation Loss: 1.2510, Validation Accuracy: 63.65%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [6/20], Train Loss: 1.0317, Validation Loss: 1.0397, Validation Accuracy: 68.83%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [7/20], Train Loss: 0.9513, Validation Loss: 0.9510, Validation Accuracy: 71.65%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [8/20], Train Loss: 0.9137, Validation Loss: 0.9678, Validation Accuracy: 70.87%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [9/20], Train Loss: 0.8692, Validation Loss: 0.9294, Validation Accuracy: 71.89%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [10/20], Train Loss: 0.8349, Validation Loss: 0.9308, Validation Accuracy: 70.97%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [11/20], Train Loss: 0.8027, Validation Loss: 0.9484, Validation Accuracy: 71.60%\n",
      "Validation loss did not improve. Patience: 2/3\n",
      "Epoch [12/20], Train Loss: 0.7780, Validation Loss: 0.8024, Validation Accuracy: 75.86%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [13/20], Train Loss: 0.7465, Validation Loss: 0.8658, Validation Accuracy: 73.11%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [14/20], Train Loss: 0.7338, Validation Loss: 0.7677, Validation Accuracy: 76.29%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [15/20], Train Loss: 0.7199, Validation Loss: 0.8828, Validation Accuracy: 73.13%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [16/20], Train Loss: 0.6981, Validation Loss: 0.7610, Validation Accuracy: 76.44%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [17/20], Train Loss: 0.6795, Validation Loss: 0.8153, Validation Accuracy: 75.13%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [18/20], Train Loss: 0.6633, Validation Loss: 0.7600, Validation Accuracy: 76.61%\n",
      "Validation loss improved! Saving model...\n",
      "Epoch [19/20], Train Loss: 0.6538, Validation Loss: 0.7829, Validation Accuracy: 75.23%\n",
      "Validation loss did not improve. Patience: 1/3\n",
      "Epoch [20/20], Train Loss: 0.6383, Validation Loss: 0.7432, Validation Accuracy: 77.29%\n",
      "Validation loss improved! Saving model...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeedForwardNN(input_size=input_size, num_classes=num_classes, hidden_size=288).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)  # Reduce LR by 10x every 5 epochs\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "counter = 0\n",
    "train_model(num_epochs, data_loader, val_loader, device, model, criterion, optimizer, scheduler, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"FeedForward.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7278, Test Accuracy: 76.98%\n"
     ]
    }
   ],
   "source": [
    "dataset_test = CustomImageDataset(csv_dir=\"ascii_file_counts.csv\", data_dir=\"test\")\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "test_model(model, data_loader_test, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(n_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)  # Reduce LR by 10x every 5 epochs\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training step\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation step\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(data_loader):.4f}, \"\n",
    "          f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        print(\"Validation loss improved! Saving model...\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, data_loader_test, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_LSTM(n_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)  # Reduce LR by 10x every 5 epochs\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "counter = 0\n",
    "train_model(num_epochs, data_loader, val_loader, device, model, criterion, optimizer, scheduler, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, data_loader_test, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNTransformer(n_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = .2, patience =10)  # Reduce LR by 10x every 5 epochs\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "counter = 0\n",
    "train_model(num_epochs, data_loader, val_loader, device, model, criterion, optimizer, scheduler, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, data_loader_test, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load(\"transformer.pth\")\n",
    "test_model(test,data_loader_test, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
